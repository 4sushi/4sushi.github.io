

## q3


• Maintenance d'un cluster big data :
    - Ajout et montée de version de services sur Cloudera Manager
    - Benchmark des bases de données : performance, usage mémoire, usage disque et contrôle de la haute disponibilité
    - Gestion de l'intégration continue, de la portabilité des codes et des différents environnements de développement
    - Mise en place de mesures de sécurité : contrôle des accès et des services réseaux
    - Monitoring de services et amélioration de la configuration pour optimiser les ressources
• Mise en place de scripts pour alimenter un data lake :
    - Migration de base de données relationnelles vers l'infrastructure big data 
    - Alimentation de nouveaux flux de données (streaming, API)
    - Intégration de fichiers plats volumineux
    - Sauvegarde automatique des données du datalake sur un autre réseau
• Traitement des données :
    - Nettoyage et contrôle de la qualité des données (python, pandas)
    - Optimisation de la performance de scripts avec du multiprocessing et des calculs distribués (Spark)
    - Conception de nouvelles structure de table pour optimiser les performances des requêtes, prise en compte des partitions (Impala/Cassandra)
    - Mise en place de tests automatisés pour contrôler toutes la chaîne de traitement des données (python, API, unittest)
    - Rédaction d'un processus complet du traitement de la donnée allant de l'acquistion à la mise à disposition des données aux clients finaux
• Développement de solutions :
    - Application d'analyse de rapports financiers (python, selenium)
    - Dashboard pour monitorer la partie acquisition de données (python, pandas, dash)
    - Reporting sur Slack et par email des anomalies

Mots clés :

BIG DATA : Cloudera Manager / Kudu / Impala / HDFS / Spark / Spark RDD / Spark dataframe / Hive / HUE / Kafka / Cassandra
SERVEUR : Cluster linux / cloud Amazon Web Services EC2 / AWS S3 / cloud OVH / Kerberos / Sentry / parefeu / crontab / nginx / pm2
PYTHON : pandas dataframe / scrapy / selenium / plotly / Dash / matplotlib / unittest / multiprocessing / logger / docstring / pickle 
DEV : nodejs / express / API / mongoDB / Swagger / MySQL / SQL 
PROCESS : automated task / integration continue / Docker / git 
FORMAT : JSON serDe / Parquet / Snappy / Gzip  
OTHER : confluence / méthodes agile / SCRUM


Projet personnel - Réalisation d'une plateforme de recommandation d'artistes de musique électronique

Projet personnel en cours de réalisation sur mon temps libre. Réalisation d'une plateforme de recommandation d'artistes de musique électronique.

• Mise en place d'une infrastructure Big data from scratch (Apache Cassandra, cloud AWS)
• Développement de scripts d'acquisitions de données sur différentes sources (python, scrapy)
• Analyse de données pour calculer des correlations entre artistes (python, pandas)
• Structuration des données pour être utilisée avec la plateforme web (nodejs, mongoDB)
• Réalisation d'une plateforme web  (nodeJS, express, vueJS)
• Configuration d'un server web sur AWS (nginx, pm2)

Mots clés :

BIG DATA : Cassandra
SERVEUR : Cluster linux / cloud Amazon Web Services EC2 / AWS S3 / crontab / nginx / pm2
PYTHON : pandas dataframe / scrapy / selenium / plotly
DEV : nodejs / express / API / mongoDB 
